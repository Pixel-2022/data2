{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7gEg4DRBwbO"
      },
      "source": [
        "\n",
        "# Overview\n",
        "This CodeLab demonstrates how to build a fused TFLite LSTM model for MNIST recognition using Keras, and how to convert it to TensorFlow Lite.\n",
        "\n",
        "The CodeLab is very similar to the Keras LSTM [CodeLab](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/examples/experimental_new_converter/keras_lstm.ipynb). However, we're creating fused LSTM ops rather than the unfused versoin.\n",
        "\n",
        "Also note: We're not trying to build the model to be a real world application, but only demonstrate how to use TensorFlow Lite. You can a build a much better model using CNN models. For a more canonical lstm codelab, please see [here](https://github.com/keras-team/keras/blob/master/examples/imdb_lstm.py)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1v9muouWCrLA"
      },
      "source": [
        "\n",
        "# Step 0: Prerequisites\n",
        "It's recommended to try this feature with the newest TensorFlow nightly pip build."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P0bSI6A5AWaT",
        "outputId": "4d562edb-185b-4cbb-9520-2ba99dd775a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tf-nightly\n",
            "  Downloading tf_nightly-2.11.0.dev20220903-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (584.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 584.5 MB 4.5 kB/s \n",
            "\u001b[?25hCollecting tb-nightly~=2.11.0.a\n",
            "  Downloading tb_nightly-2.11.0a20220903-py3-none-any.whl (5.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.9 MB 35.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (21.3)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (1.15.0)\n",
            "Collecting keras-nightly~=2.11.0.dev\n",
            "  Downloading keras_nightly-2.11.0.dev2022090307-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 56.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (4.1.1)\n",
            "Collecting tf-estimator-nightly~=2.11.0.dev\n",
            "  Downloading tf_estimator_nightly-2.11.0.dev2022090308-py2.py3-none-any.whl (439 kB)\n",
            "\u001b[K     |████████████████████████████████| 439 kB 49.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (1.47.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (1.2.0)\n",
            "Collecting gast<=0.4.0,>=0.2.1\n",
            "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (3.3.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (0.26.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (3.17.3)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (14.0.6)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (1.6.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (57.4.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (1.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (1.14.1)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (2.0.7)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (1.21.6)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tf-nightly) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tf-nightly) (1.5.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tb-nightly~=2.11.0.a->tf-nightly) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tb-nightly~=2.11.0.a->tf-nightly) (1.8.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tb-nightly~=2.11.0.a->tf-nightly) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tb-nightly~=2.11.0.a->tf-nightly) (1.0.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tb-nightly~=2.11.0.a->tf-nightly) (1.35.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tb-nightly~=2.11.0.a->tf-nightly) (3.4.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tb-nightly~=2.11.0.a->tf-nightly) (0.4.6)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tb-nightly~=2.11.0.a->tf-nightly) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tb-nightly~=2.11.0.a->tf-nightly) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tb-nightly~=2.11.0.a->tf-nightly) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tb-nightly~=2.11.0.a->tf-nightly) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tb-nightly~=2.11.0.a->tf-nightly) (4.12.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tb-nightly~=2.11.0.a->tf-nightly) (3.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tb-nightly~=2.11.0.a->tf-nightly) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tb-nightly~=2.11.0.a->tf-nightly) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tb-nightly~=2.11.0.a->tf-nightly) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tb-nightly~=2.11.0.a->tf-nightly) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tb-nightly~=2.11.0.a->tf-nightly) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tb-nightly~=2.11.0.a->tf-nightly) (3.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tf-nightly) (3.0.9)\n",
            "Installing collected packages: tf-estimator-nightly, tb-nightly, keras-nightly, gast, tf-nightly\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.5.3\n",
            "    Uninstalling gast-0.5.3:\n",
            "      Successfully uninstalled gast-0.5.3\n",
            "Successfully installed gast-0.4.0 keras-nightly-2.11.0.dev2022090307 tb-nightly-2.11.0a20220903 tf-estimator-nightly-2.11.0.dev2022090308 tf-nightly-2.11.0.dev20220903\n"
          ]
        }
      ],
      "source": [
        "!pip install tf-nightly"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zeo4IA1xC4O8"
      },
      "source": [
        "# Step 1: Build the MNIST LSTM model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yMtp56hRBvHe"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "liff5rfJtrBA",
        "outputId": "da15909d-6797-4f9b-bf7a-64107d99112c"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-a43d06ddb26b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0mlabels2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m \u001b[0my_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0my_data2\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/np_utils.py\u001b[0m in \u001b[0;36mto_categorical\u001b[0;34m(y, num_classes, dtype)\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0mcategorical\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m     \u001b[0mcategorical\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0moutput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0mcategorical\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcategorical\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: index 17 is out of bounds for axis 1 with size 4"
          ]
        }
      ],
      "source": [
        "from keras.layers.rnn.dropout_rnn_cell_mixin import DropoutRNNCellMixin\n",
        "from tensorflow.python.ops.nn_ops import dropout\n",
        "from tensorflow.python.ops.gen_nn_ops import relu\n",
        "\n",
        "actions = [\n",
        "    'left',\n",
        "    'right',\n",
        "    'hi',\n",
        "    'look'\n",
        "    \n",
        "]\n",
        "\n",
        "data = np.concatenate([\n",
        "    \n",
        "    np.load('seq_hi_1_1661663755.npy'),\n",
        "    np.load('seq_hi_2_1661663809.npy'),\n",
        "    np.load('seq_hi_3_1661663843.npy'),\n",
        "    np.load('seq_hi_4_1661663887.npy'),\n",
        "    np.load('seq_eat_1_1661663981.npy'),\n",
        "    np.load('seq_eat_2_1661664034.npy'),\n",
        "    np.load('seq_eat_3_1661664070.npy'),\n",
        "    np.load('seq_eat_4_1661664107.npy'),\n",
        "    np.load('seq_bob_1_1661664188.npy'),\n",
        "    np.load('seq_bob_2_1661664238.npy'),\n",
        "    np.load('seq_bob_3_1661664273.npy'),\n",
        "    np.load('seq_bob_4_1661664322.npy'),\n",
        "    np.load('seq_meet_1_1661664416.npy'),\n",
        "    np.load('seq_meet_2_1661664458.npy'),\n",
        "    np.load('seq_meet_3_1661664486.npy'),\n",
        "    np.load('seq_meet_4_1661664522.npy')\n",
        "    # np.load('keras_lstm/seq_look_2_1660103472.npy'),\n",
        "    # np.load('keras_lstm/seq_look_4_1660105439.npy'),\n",
        "    # np.load('keras_lstm/seq_look_5_1660105557.npy'),\n",
        "    # np.load('keras_lstm/seq_look_6_1660105715.npy'),\n",
        "    # np.load('keras_lstm/seq_look_7_1660105752.npy'),\n",
        "    # np.load('keras_lstm/seq_look_8_1660105786.npy'),\n",
        "    # np.load('keras_lstm/seq_look_9_1660105825.npy'),\n",
        "    # np.load('keras_lstm/seq_look_10_1660105849.npy'),\n",
        "    # np.load('keras_lstm/seq_look_12_1660105907.npy'),\n",
        "    # np.load('keras_lstm/seq_look_13_1660105955.npy'),\n",
        "    # np.load('keras_lstm/seq_look_14_1660106613.npy'),\n",
        "    # np.load('keras_lstm/seq_look_15_1660106681.npy'),\n",
        "    # np.load('keras_lstm/seq_look_16_1660107168.npy'),\n",
        "    # np.load('keras_lstm/seq_look_17_1660107203.npy')\n",
        "    \n",
        "    \n",
        "], axis=0)   \n",
        "data.shape\n",
        "\n",
        "data2 = np.concatenate([\n",
        "    \n",
        "    np.load('seq_hi_5_1661663923.npy'),\n",
        "    np.load('seq_eat_5_1661664150.npy'),\n",
        "    np.load('seq_bob_5_1661664366.npy'),\n",
        "    np.load('seq_meet_5_1661664574.npy')\n",
        "    \n",
        "    \n",
        "], axis=0)  \n",
        "data.shape\n",
        "\n",
        "x_data = data[:,:,:-1]\n",
        "x_data2 = data2[:,:,:-1]\n",
        "labels = data[:,0,-1]\n",
        "labels2 = data2[:, 0, -1]\n",
        "y_data=tf.keras.utils.to_categorical(labels, num_classes=len(actions))\n",
        "\n",
        "y_data2 =tf.keras.utils.to_categorical(labels2, num_classes=len(actions))\n",
        "\n",
        "x_data = x_data.astype(np.float32)\n",
        "y_data = labels.astype(np.float32)\n",
        "\n",
        "x_data2 = x_data2.astype(np.float32)\n",
        "y_data2 = y_data2.astype(np.float32)\n",
        "\n",
        "x_train = x_data\n",
        "\n",
        "\n",
        "x_val = x_data2\n",
        "y_train = y_data\n",
        "\n",
        "y_val = y_data2\n",
        "\n",
        "\n",
        "# model2 = tf.keras.models.Sequential([\n",
        "#    tf.keras.layers.Input(shape=(30,432),name='input'),\n",
        "#    tf.keras.layers.LSTM(20, time_major=False, return_sequences=True),\n",
        "#    tf.keras.layers.Flatten(),\n",
        "#    tf.keras.layers.Dense(3, activation=tf.nn.softmax, name='output')\n",
        "# ])\n",
        "\n",
        "model2 = tf.keras.models.Sequential([\n",
        "   tf.keras.layers.Input(shape=(30,368),name='input'),\n",
        "   tf.keras.layers.LSTM(64, time_major=False, return_sequences=True),\n",
        "   tf.keras.layers.Dropout(0.3),\n",
        "   tf.keras.layers.Dense(32, activation=tf.nn.relu),\n",
        "   tf.keras.layers.Dense(32, activation=tf.nn.relu),\n",
        "   tf.keras.layers.Dropout(0.3),\n",
        "   tf.keras.layers.Dropout(0.3),\n",
        "   tf.keras.layers.Dense(32, activation=tf.nn.relu),\n",
        "   tf.keras.layers.Flatten(),\n",
        "   tf.keras.layers.Dense(4, activation=tf.nn.softmax, name='output')\n",
        "])\n",
        "model2.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model2.summary()\n",
        "\n",
        "_EPOCHS = 200\n",
        "\n",
        "\n",
        "model2.fit(x_train, labels, epochs=_EPOCHS)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IQtjKcMYC_nD",
        "outputId": "265e95fb-bc32-4b36-c8c9-e5f1a2aa1662"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_2 (LSTM)               (None, 28, 20)            3920      \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 560)               0         \n",
            "                                                                 \n",
            " output (Dense)              (None, 10)                5610      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 9,530\n",
            "Trainable params: 9,530\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Input(shape=(28, 28), name='input'),\n",
        "    tf.keras.layers.LSTM(20, time_major=False, return_sequences=True),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(10, activation=tf.nn.softmax, name='output')\n",
        "])\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qS_79wHVDcri"
      },
      "source": [
        "# Step 2: Train & Evaluate the model.\n",
        "We will train the model using MNIST data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-yEAraXGDlcQ",
        "outputId": "b07d529a-8f82-487a-967f-bc16d76ca2d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 23s 11ms/step - loss: 0.3244 - accuracy: 0.9038\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 18s 10ms/step - loss: 0.1193 - accuracy: 0.9645\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 18s 10ms/step - loss: 0.0886 - accuracy: 0.9728\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 20s 11ms/step - loss: 0.0729 - accuracy: 0.9776\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 19s 10ms/step - loss: 0.0624 - accuracy: 0.9811\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.058012884110212326, 0.9817000031471252]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load MNIST dataset.\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "x_train = x_train.astype(np.float32)\n",
        "x_test = x_test.astype(np.float32)\n",
        "\n",
        "# Change this to True if you want to test the flow rapidly.\n",
        "# Train with a small dataset and only 1 epoch. The model will work poorly\n",
        "# but this provides a fast way to test if the conversion works end to end.\n",
        "_FAST_TRAINING = False\n",
        "_EPOCHS = 5\n",
        "if _FAST_TRAINING:\n",
        "  _EPOCHS = 1\n",
        "  _TRAINING_DATA_COUNT = 1000\n",
        "  x_train = x_train[:_TRAINING_DATA_COUNT]\n",
        "  y_train = y_train[:_TRAINING_DATA_COUNT]\n",
        "\n",
        "\n",
        "model.fit(x_train, y_train, epochs=_EPOCHS)\n",
        "model.evaluate(x_test, y_test, verbose=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5pGyWlkJDpMQ"
      },
      "source": [
        "# Step 3: Convert the Keras model to TensorFlow Lite model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WmT_Q7xicc6l",
        "outputId": "6a5ff107-fcb1-47e2-d611-f93516ea8174"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_19_layer_call_fn, lstm_cell_19_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "541976"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "run_model = tf.function(lambda x: model2(x))\n",
        "# This is important, let's fix the input size.\n",
        "BATCH_SIZE = 1\n",
        "STEPS = 30\n",
        "INPUT_SIZE = 368\n",
        "concrete_func = run_model.get_concrete_function(\n",
        "    tf.TensorSpec([BATCH_SIZE, STEPS, INPUT_SIZE], model2.inputs[0].dtype))\n",
        "\n",
        "# model directory.\n",
        "MODEL_DIR = \"AAA\"\n",
        "model2.save(MODEL_DIR, save_format=\"tf\", signatures=concrete_func)\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(MODEL_DIR)\n",
        "#converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]\n",
        "tflite_model = converter.convert()\n",
        "open(\"AAAA.tflite\", \"wb\").write(tflite_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tB1NZBUHDogR",
        "outputId": "b972ffce-02be-4ba6-adbe-aa205eb8ce96"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_33_layer_call_fn, lstm_cell_33_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "41220"
            ]
          },
          "execution_count": 86,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "run_model = tf.function(lambda x: model(x))\n",
        "# This is important, let's fix the input size.\n",
        "BATCH_SIZE = 1\n",
        "STEPS = 28\n",
        "INPUT_SIZE = 28\n",
        "concrete_func = run_model.get_concrete_function(\n",
        "    tf.TensorSpec([BATCH_SIZE, STEPS, INPUT_SIZE], model.inputs[0].dtype))\n",
        "\n",
        "# model directory.\n",
        "MODEL_DIR = \"keras_lstm\"\n",
        "model.save(MODEL_DIR, save_format=\"tf\", signatures=concrete_func)\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(MODEL_DIR)\n",
        "tflite_model = converter.convert()\n",
        "open(\"BBBB.tflite\", \"wb\").write(tflite_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "INFyl-J3FAOY"
      },
      "source": [
        "# Step 4: Check the converted TensorFlow Lite model.\n",
        "Now load the TensorFlow Lite model and use the TensorFlow Lite python interpreter to verify the results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0-b0IKK2FGuO",
        "outputId": "6ae71edf-d501-472a-97e0-c58bfabf61a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'name': 'serving_default_x:0', 'index': 0, 'shape': array([ 1, 28, 28], dtype=int32), 'shape_signature': array([ 1, 28, 28], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n",
            "[{'name': 'StatefulPartitionedCall:0', 'index': 21, 'shape': array([ 1, 10], dtype=int32), 'shape_signature': array([ 1, 10], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "Done. The result of TensorFlow matches the result of TensorFlow Lite.\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "Done. The result of TensorFlow matches the result of TensorFlow Lite.\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "Done. The result of TensorFlow matches the result of TensorFlow Lite.\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "Done. The result of TensorFlow matches the result of TensorFlow Lite.\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "Done. The result of TensorFlow matches the result of TensorFlow Lite.\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "Done. The result of TensorFlow matches the result of TensorFlow Lite.\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "Done. The result of TensorFlow matches the result of TensorFlow Lite.\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "Done. The result of TensorFlow matches the result of TensorFlow Lite.\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "Done. The result of TensorFlow matches the result of TensorFlow Lite.\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "Done. The result of TensorFlow matches the result of TensorFlow Lite.\n"
          ]
        }
      ],
      "source": [
        "# Run the model with TensorFlow to get expected results.\n",
        "TEST_CASES = 10\n",
        "\n",
        "# Run the model with TensorFlow Lite\n",
        "interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
        "interpreter.allocate_tensors()\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "print(input_details)\n",
        "print(output_details)\n",
        "for i in range(TEST_CASES):\n",
        "  expected = model.predict(x_test[i:i+1])\n",
        "  interpreter.set_tensor(input_details[0][\"index\"], x_test[i:i+1, :, :])\n",
        "  interpreter.invoke()\n",
        "  result = interpreter.get_tensor(output_details[0][\"index\"])\n",
        "\n",
        "  # Assert if the result of TFLite model is consistent with the TF model.\n",
        "  np.testing.assert_almost_equal(expected, result, decimal=5)\n",
        "  print(\"Done. The result of TensorFlow matches the result of TensorFlow Lite.\")\n",
        "\n",
        "  # Please note: TfLite fused Lstm kernel is stateful, so we need to reset\n",
        "  # the states.\n",
        "  # Clean up internal states.\n",
        "  interpreter.reset_all_variables()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W5pOnQ56mHlN",
        "outputId": "b9550e55-696c-40a9-92a0-cec2fb2987ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'name': 'serving_default_x:0', 'index': 0, 'shape': array([  1,  30, 432], dtype=int32), 'shape_signature': array([ -1,  30, 432], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n",
            "[{'name': 'StatefulPartitionedCall:0', 'index': 29, 'shape': array([1, 3], dtype=int32), 'shape_signature': array([-1,  3], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "Done. The result of TensorFlow matches the result of TensorFlow Lite.\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Done. The result of TensorFlow matches the result of TensorFlow Lite.\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "Done. The result of TensorFlow matches the result of TensorFlow Lite.\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Done. The result of TensorFlow matches the result of TensorFlow Lite.\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "Done. The result of TensorFlow matches the result of TensorFlow Lite.\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "Done. The result of TensorFlow matches the result of TensorFlow Lite.\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Done. The result of TensorFlow matches the result of TensorFlow Lite.\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Done. The result of TensorFlow matches the result of TensorFlow Lite.\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Done. The result of TensorFlow matches the result of TensorFlow Lite.\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Done. The result of TensorFlow matches the result of TensorFlow Lite.\n"
          ]
        }
      ],
      "source": [
        "# Run the model with TensorFlow to get expected results.\n",
        "TEST_CASES = 10\n",
        "\n",
        "# Run the model with TensorFlow Lite\n",
        "interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
        "interpreter.allocate_tensors()\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "print(input_details)\n",
        "print(output_details)\n",
        "for i in range(TEST_CASES):\n",
        "  expected = model2.predict(x_val[i:i+1])\n",
        "  interpreter.set_tensor(input_details[0][\"index\"], x_val[i:i+1, :, :])\n",
        "  interpreter.invoke()\n",
        "  result = interpreter.get_tensor(output_details[0][\"index\"])\n",
        "\n",
        "  # Assert if the result of TFLite model is consistent with the TF model.\n",
        "  np.testing.assert_almost_equal(expected, result, decimal=5)\n",
        "  print(\"Done. The result of TensorFlow matches the result of TensorFlow Lite.\")\n",
        "\n",
        "  # Please note: TfLite fused Lstm kernel is stateful, so we need to reset\n",
        "  # the states.\n",
        "  # Clean up internal states.\n",
        "  interpreter.reset_all_variables()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cf6KC9fbFY5f"
      },
      "source": [
        "# Step 5: Let's inspect the converted TFLite model.\n",
        "\n",
        "Let's check the model, you can see the LSTM will be in it's fused format.\n",
        "\n",
        "![Fused LSTM](https://raw.githubusercontent.com/tensorflow/tensorflow/master/tensorflow/lite/examples/experimental_new_converter/keras_lstm.png)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}